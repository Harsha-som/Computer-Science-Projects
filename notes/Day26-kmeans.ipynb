{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b0e7ca52",
   "metadata": {},
   "source": [
    "# The One Goal For Today\n",
    "\n",
    "Understand how normalization first can lead to better or more efficient clustering and classification models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "811722d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "import scipy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6243b190",
   "metadata": {},
   "source": [
    "# Load and Look at Your Data\n",
    "\n",
    "The data set we wil be analyzing is our usual car dataset from Craigslist. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c8571c1f",
   "metadata": {},
   "source": [
    "First we load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca359103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ['0', '1', '1000', '10000', '10199', '10200', '10300', '10399', '10400', '10450', '10475', '10488', '10491', '10494', '10495', '10498', '10500', '10550', '10600', '10650', '10691', '10695', '10700', '10800', '10844', '10888', '10900', '10950', '10977', '10980', '10988', '10989', '10990', '10995', '10999', '11000', '11011', '11200', '11250', '11272', '11375', '11380', '11450', '11480', '11493', '11495', '11499', '1150', '11500', '11515', '11550', '11600', '11700', '11795', '11900', '11901', '1195', '11950', '11976', '11985', '11987', '11988', '11990', '11995', '11997', '11999', '1200', '12000', '12177', '12250', '12400', '12450', '12488', '12495', '12499', '1250', '12500', '12588', '12595', '1275', '12775', '12835', '12875', '12889', '12900', '1295', '12950', '12977', '12990', '12995', '12999', '1300', '13000', '13299', '13300', '13325', '13400', '13440', '13450', '13488', '13490', '13494', '13495', '13500', '13599', '13600', '13650', '13750', '13753', '13795', '13850', '13860', '13888', '13899', '13900', '13950', '13977', '13980', '13985', '13988', '13990', '13995', '13999', '1400', '14000', '14200', '14249', '14250', '14300', '14450', '14495', '14499', '1450', '14500', '14588', '14627', '14700', '14750', '14800', '14811', '149', '14900', '14950', '14977', '14985', '14990', '14991', '14995', '14998', '14999', '1500', '15000', '15490', '15495', '1550', '15500', '15700', '15749', '15800', '15833', '15895', '159', '15939', '15950', '15990', '15995', '15997', '15998', '15999', '1600', '16000', '16199', '16299', '16300', '16495', '16499', '1650', '16500', '16777', '16788', '16800', '16872', '16888', '169', '16900', '16950', '16988', '16990', '16995', '16999', '1700', '17000', '17050', '17250', '17300', '17312', '17333', '17488', '17491', '17495', '1750', '17500', '17695', '17736', '17788', '17900', '17936', '17960', '17990', '17995', '17999', '1800', '18000', '18200', '18255', '18371', '18477', '18495', '18499', '1850', '18500', '18600', '18749', '18775', '18799', '18800', '18895', '18899', '189', '1895', '18988', '18990', '18995', '18997', '18999', '190', '1900', '19000', '19300', '19495', '195', '1950', '19500', '19700', '19750', '19798', '19800', '199', '19900', '1995', '1999', '19990', '19995', '19998', '19999', '200', '2000', '20000', '20500', '20699', '20800', '20900', '20933', '20950', '20980', '20995', '20999', '21000', '215', '21500', '21700', '2181', '21950', '21968', '21995', '21999', '2200', '22000', '2250', '22900', '2295', '22988', '22990', '2300', '23000', '23380', '23495', '23498', '2350', '23500', '2390', '23995', '2400', '24444', '24513', '2485', '2488', '2495', '2499', '2500', '25000', '2550', '25500', '2599', '25995', '2600', '26000', '2650', '26500', '268', '2695', '2699', '26995', '2700', '27500', '27675', '278', '2790', '2799', '2800', '2850', '28888', '28900', '2900', '2935', '2950', '29500', '2975', '299', '2990', '2995', '2999', '29993', '30', '300', '3000', '30000', '3100', '3150', '31977', '3200', '3250', '3290', '3300', '3400', '3449', '3450', '3490', '3495', '3497', '3499', '34999', '3500', '35000', '3550', '3595', '3599', '35995', '3600', '36294', '3650', '36900', '3695', '3699', '3700', '3750', '37500', '3795', '3800', '3850', '3890', '3900', '3950', '3980', '3988', '3990', '3995', '3999', '4000', '4100', '41000', '415', '4150', '4200', '4250', '42900', '4295', '4299', '4300', '4399', '4400', '4450', '4475', '4490', '4495', '4499', '4500', '4550', '4595', '4600', '4689', '4700', '4740', '4750', '4795', '4800', '4850', '4888', '4895', '4899', '4900', '4950', '4975', '4985', '4988', '4990', '4991', '4995', '4999', '500', '5000', '5100', '5200', '5250', '5295', '5299', '5300', '5350', '5395', '5400', '5450', '5490', '5495', '5499', '550', '5500', '55000', '5590', '5595', '5599', '5600', '5695', '5700', '5706', '5733', '5750', '5775', '5799', '5800', '5850', '5875', '5877', '5900', '5943', '5950', '5975', '5990', '5991', '5995', '5997', '5998', '5999', '600', '6000', '6100', '6150', '6200', '6210', '6250', '6295', '6299', '6300', '6315', '6395', '6400', '6480', '6490', '6495', '6499', '650', '6500', '6550', '6575', '6590', '6591', '6595', '6599', '6600', '6650', '6677', '6680', '6700', '6750', '6775', '6777', '6795', '6799', '6800', '6850', '6900', '6950', '6965', '6975', '6978', '6980', '6988', '6990', '6995', '6999', '7', '7000', '7100', '7200', '7295', '7300', '7400', '7450', '7490', '7492', '7495', '7499', '750', '7500', '7595', '7600', '7695', '7698', '7700', '7733', '7750', '7772', '7788', '7790', '7795', '7800', '7821', '7848', '7850', '7867', '7875', '7877', '7885', '7895', '7898', '7900', '7943', '7950', '7980', '7988', '7990', '7995', '7999', '800', '8000', '8099', '8150', '8199', '8200', '8249', '8250', '8377', '8400', '8450', '8488', '8490', '8495', '8498', '8499', '85', '850', '8500', '8550', '8573', '8595', '8600', '8650', '8700', '8747', '8749', '8750', '8795', '8800', '8850', '8870', '8888', '8895', '8899', '8900', '8950', '8975', '8977', '8988', '8990', '8995', '8998', '8999', '900', '9000', '9100', '9140', '9200', '9218', '9250', '9295', '9299', '9395', '9400', '9450', '9470', '9488', '9490', '9495', '9498', '9499', '9500', '9597', '9663', '9673', '9677', '9680', '9685', '9750', '9800', '9877', '9890', '9899', '9900', '995', '9950', '9980', '9988', '9989', '999', '9990', '9995', '9997', '9999']\n",
      "1 ['1999', '2000', '2001', '2002', '2003', '2004', '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021']\n",
      "2 ['hyundai', 'kia']\n",
      "3 ['accent', 'accent 4dsd', 'accent gl 4dr sedan', 'accent gls', 'accent gls 4dr sedan', 'accent gs', 'accent hatchback', 'accent se', 'accent se hatchback 4d', 'accent se sedan 4d', 'accent sedan', 'amanti', 'amanti base 4dr sedan', 'azera', 'azera limited', 'azera limited 4dr sedan', 'azera se', 'borrego', 'borrego lx', 'cadenza', 'cadenza limited-sxl', 'cadenza premium', 'cadenza premium sedan 4d', 'corento', 'elantra', 'elantra blue', 'elantra coupe', 'elantra gls', 'elantra gls 4dr sedan', 'elantra gls 4dr sedan 6', 'elantra gls sedan', 'elantra gs coupe', 'elantra gt', 'elantra gt hatchback', 'elantra gt hatchback 4d', 'elantra gt hatchback-4d', 'elantra limited', 'elantra limited sedan 4d', 'elantra pzev', 'elantra se', 'elantra se 4dr sedan', 'elantra se sedan 4d', 'elantra se value edition', 'elantra sel', 'elantra sport', 'elantra touring', 'elantra touring se', 'elentra', 'elentra gls', 'elentra sport', 'elentra touring', 'entourage', 'entourage limited', 'equus', 'equus signature', 'equus ultimate', 'fe', 'forte', 'forte 4dr sdn lx', 'forte 5', 'forte 5 sxt gdi turbo', 'forte 5-door', 'forte ex', 'forte ex hatchback 5d', 'forte ex sedan 4d', 'forte fe', 'forte fe cvt', 'forte g-line', 'forte gt line', 'forte gt-line', 'forte koup', 'forte lx', 'forte lx 2.0l', 'forte lx plus', 'forte lx sedan', 'forte lx sedan 4d', 'forte lx sedan 6a', 'forte lxs', 'forte premium 2.0 gdi', 'forte sedan', 'forte sx', 'forte5', 'forte5 lx', 'genesis', 'genesis 3.8', 'genesis 3.8 sedan 4d', 'genesis 3.80', 'genesis 3.8l', 'genesis 3.8l v6', 'genesis 4.6', 'genesis 5.0', 'genesis coupe', 'genesis coupe 2.0t', 'genesis coupe 3.8', 'genesis coupe 3.8 2d', 'genesis coupe 3.8 track', 'genesis sedan', 'ioniq', 'ioniq hybrid', 'ioniq plug-in hybrid', 'k5 lxs', 'kona', 'kona se', 'kona sel', 'niro', 'niro lx', 'niro lx hybrid', 'optiam fe', 'optima', 'optima 4dr sdn lx', 'optima ex', 'optima ex 4dr sedan', 'optima ex premium', 'optima ex sedan', 'optima ex sedan 4d', 'optima ex sedan automatic', 'optima ex-gdi', 'optima fe', 'optima gdi', 'optima hybrid', 'optima lx', 'optima lx 4dr sedan', 'optima lx sedan 4 door', 'optima lx sedan 4d', 'optima sx', 'optima sx turbo', 'optima sxl', 'optima sxl turbo', 'optima turbo lx', 'optimia premium', 'optimia sx premium', 'optioma', 'rio', 'rio - lx sedan 4 dr.', 'rio 5', 'rio base', 'rio ex', 'rio ex 1.6l', 'rio gdi', 'rio lx', 'rio lx sedan 4d', 'rio s', 'rio sedan 4d', 'rio sx', 'rio sx 4 door', 'rio5', 'rio5 lx', 'rio5 sx', 'rio5 sx 5 speed', 'rondo', 'rondo ex', 'rondo lx', 's', 'santa fe', 'santa fe 2.0t sport', 'santa fe 4x4 gls', 'santa fe awd', 'santa fe fwd', 'santa fe gls', 'santa fe gls awd', 'santa fe limited', 'santa fe limited awd', 'santa fe limited sport', 'santa fe se', 'santa fe se automatic', 'santa fe se awd', 'santa fe sel awd', 'santa fe sport', 'santa fe sport 2.4', 'santa fe sport 2.4l', 'santa fe sport awd', 'santafe', 'sante fe', 'sante fe - se', 'sante fe limited awd', 'sante fe se', 'sante fe se awd', 'sante fe sel', 'sante fe sport 2.0t', 'sante fe sport popular', 'sedona', 'sedona ex', 'sedona lx', 'sedona lx minivan 4d', 'sedona lx van', 'sedona sxl 3.3l v6', 'sedona van', 'seltos lx', 'sodona', 'sol', 'sonata', 'sonata - gls', 'sonata 2.0t limited', 'sonata 2.4 l', 'sonata 2.4l limited', 'sonata 2.4l se', 'sonata 2.4l sport', 'sonata 2007', 'sonata 2013', 'sonata echo', 'sonata gls', 'sonata gls 4dr sedan', 'sonata hybrid', 'sonata hybrid limited', 'sonata hybrid se', 'sonata limited', 'sonata limited 2.0t', 'sonata limited 2.0t se', 'sonata limited 2010', 'sonata limited pzev', 'sonata limited sedan 4d', 'sonata limited v-6', 'sonata limited￼', 'sonata lx', 'sonata se', 'sonata se 4dr sedan', 'sonata sedan 4d', 'sonata sel', 'sonata sport', 'sonata sport 2.0t', 'sonata sport 2.0t ltd', 'sonata sport+', 'sonata v6', 'sorent0', 'sorento', 'sorento 3.6', 'sorento awd', 'sorento awd sxl gdi', 'sorento ex', 'sorento ex 4wd', 'sorento ex awd', 'sorento ex v6', 'sorento exl', 'sorento l', 'sorento lx', 'sorento lx 2.4l awd', 'sorento lx 2wd', 'sorento lx 4wd', 'sorento lx awd', 'sorento lx sport 4wd', 'sorento lx sport utility', 'sorento lx suv', 'sorento lx v6', 'sorento sx', 'sorento sx awd', 'sorento sxl', 'sorento sxl-limited', 'sorrento', 'sorrento awd lx', 'sorrento lx', 'sorrento lx v6', 'sorrento s', 'sorrento sxl limited', 'sorrnto', 'soul', 'soul !', 'soul +', 'soul + automatic', 'soul + wagon', 'soul + wagon 4d', 'soul base', 'soul base 4dr crossover 6a', 'soul base 4dr crossover 6m', 'soul ev', 'soul ev plus', 'soul exclaim', 'soul handicap', 'soul lx', 'soul plus', 'soul plus automatic', 'soul sport', 'soul x-line', 'soul+', 'sould', 'spectra', 'spectra 5', 'spectra ex', 'spectra sx', 'spectra5', 'spectra5 sx', 'sportage', 'sportage awd', 'sportage ex', 'sportage ex 2.4l awd', 'sportage ex awd', 'sportage lx', 'sportage lx 2.4l', 'sportage lx awd', 'sportage lx fwd', 'sportage lx sport utility', 'sportage sx turbo', 'sportqage lx', 'stinger', 'stinger awd', 'stinger gt', 'telluride', 'telluride sx v6 awd', 'tiburon', 'tiburon es', 'tiburon gs', 'tiburon gs 5-spd manual', 'tiburon gt', 'tiburon gt v6', 'tiburon se', 'tucson', 'tucson 4wd ltd', 'tucson gl', 'tucson gls', 'tucson gls awd', 'tucson limited', 'tucson limited awd', 'tucson ltd 4wd', 'tucson se awd', 'tucson sport', 'tucson spt', 'tuscan gls', 'tuscon', 'tuscon gls', 'tuscon limited 4x4', 'tuscon- gls', 'veloster', 'veloster 3 door coupe', 'veloster 3dr coupe dct', 'veloster base 3dr coupe', 'veloster coupe', 'veloster coupe 3d', 'veloster hi brother', 'veloster n', 'veloster turbo', 'veloster turbo automatic', 'velostor', 'veracruz', 'veracruz fwd 4dr limited', 'veracruz gls', 'veracruz limited', 'veracruz se', 'xg 350 l', 'xg 350l', 'xg350', 'xg350 l', 'xg350l']\n",
      "4 ['excellent', 'fair', 'good', 'like new', 'new', 'salvage']\n",
      "5 ['diesel', 'electric', 'gas', 'hybrid', 'other']\n",
      "6 ['0', '1', '10', '1000', '10000', '100000', '100021', '100050', '100100', '100115', '100200', '100231', '100299', '100353', '100428', '100503', '100520', '100633', '100887', '101000', '101200', '101272', '101287', '101480', '101500', '101532', '101547', '101556', '101766', '101845', '101853', '101868', '101894', '102000', '102150', '102271', '102300', '102400', '102495', '102507', '102672', '102750', '102837', '102838', '103000', '103050', '103310', '103317', '103338', '103550', '10400', '104000', '104100', '104193', '104200', '104216', '104220', '104250', '104254', '104278', '104379', '104487', '104497', '104500', '104523', '104706', '104739', '104827', '104863', '104991', '105000', '105054', '105119', '105137', '105148', '10515', '105196', '105257', '105300', '105346', '105382', '105500', '105537', '105586', '105598', '105679', '105794', '105877', '105880', '105947', '106000', '106197', '106210', '106229', '106403', '106417', '106470', '106500', '106518', '106530', '106571', '106575', '106621', '106700', '106752', '106839', '106925', '106992', '10700', '107000', '107070', '107086', '107220', '107261', '107328', '107500', '107527', '107638', '107706', '107738', '107818', '107976', '108000', '108125', '108186', '108222', '10832', '108664', '108682', '108801', '108811', '108900', '108922', '109000', '109090', '109123', '109221', '109241', '109242', '109288', '109504', '109623', '109669', '109821', '109850', '109881', '109900', '11000', '110000', '110090', '110152', '110197', '110205', '110247', '110312', '110346', '110410', '110438', '110592', '110600', '110654', '110680', '110959', '110991', '111000', '111100', '111349', '111414', '111458', '111481', '111500', '111542', '111554', '111585', '111771', '111800', '111990', '112000', '112100', '112300', '112390', '112392', '112406', '112500', '112521', '112538', '112613', '112793', '112802', '112899', '112938', '112996', '113000', '113076', '113268', '113499', '113500', '113578', '113593', '113605', '113683', '113721', '113733', '113907', '113968', '114000', '114089', '114169', '114202', '114258', '114456', '114466', '114695', '114700', '114826', '114988', '11500', '115000', '115098', '11514', '115146', '115272', '115312', '115372', '115399', '115420', '115450', '115497', '115711', '115760', '115802', '115910', '115927', '116000', '116020', '116142', '116256', '116291', '116300', '116425', '116575', '116650', '116689', '116806', '116850', '117000', '117053', '117100', '117109', '117160', '117258', '117269', '117300', '117350', '117400', '117442', '117500', '117846', '118000', '118026', '118232', '118300', '118395', '118500', '118950', '119000', '119061', '119207', '119264', '119280', '119495', '119523', '119621', '119668', '119690', '119783', '119861', '119862', '119977', '12000', '120000', '120130', '120272', '120323', '120400', '120550', '120754', '120759', '120852', '120879', '121000', '121259', '121442', '121500', '121503', '121600', '121619', '121741', '121798', '121840', '121888', '121924', '121995', '122000', '122184', '122216', '122300', '122575', '122691', '122709', '122758', '122809', '12300', '123000', '12310', '123106', '123188', '123227', '123320', '123333', '123369', '123400', '123405', '123480', '123527', '123535', '123546', '123564', '123609', '123665', '123703', '123800', '123821', '123844', '123929', '123987', '124000', '124047', '124144', '124191', '124447', '124600', '124635', '124642', '124667', '124688', '1247', '124821', '124906', '124914', '125000', '125018', '125082', '125147', '125327', '125500', '125539', '125608', '125763', '125767', '125943', '126000', '126017', '126100', '126229', '126256', '126300', '126344', '126634', '126687', '126757', '126833', '127000', '127153', '127251', '127277', '127464', '127756', '127920', '128000', '128168', '128238', '128635', '128642', '128723', '128741', '128746', '128986', '128992', '129000', '129040', '129071', '129125', '129141', '129170', '129190', '129220', '129242', '129300', '129400', '129450', '129550', '129580', '129685', '129701', '129755', '129768', '129779', '129781', '129803', '129834', '129910', '129974', '130000', '130200', '130318', '130432', '130448', '130658', '130660', '130719', '130786', '130889', '130928', '130973', '131000', '131248', '131274', '131321', '131405', '131538', '131569', '131627', '131651', '131822', '131900', '131957', '131970', '132000', '132415', '132423', '132440', '132500', '132667', '132704', '132750', '132925', '133000', '133093', '133300', '13343', '133452', '133645', '133813', '13400', '134000', '134014', '134063', '134079', '134300', '134312', '134400', '134483', '135', '13500', '135000', '135053', '135113', '135144', '135275', '13534', '135420', '135539', '135624', '135696', '136', '136000', '136379', '136390', '136475', '136594', '136700', '136756', '136757', '136840', '136951', '136958', '137000', '137200', '137303', '137369', '137556', '13756', '137951', '138000', '138291', '138332', '138464', '138521', '138805', '138880', '138976', '139000', '139212', '139236', '139347', '139652', '139689', '139703', '139806', '139875', '14', '1400', '14000', '140000', '140048', '14036', '140567', '140580', '140866', '140988', '141000', '141050', '14147', '141700', '141706', '14184', '141870', '141963', '142000', '142310', '142365', '142813', '142981', '14300', '143000', '143105', '143178', '143180', '143400', '143429', '143450', '143504', '143810', '143910', '14400', '144000', '144068', '144132', '144622', '144739', '144747', '144967', '145000', '145006', '145048', '145126', '145463', '145507', '145752', '145770', '145789', '145841', '145909', '146000', '146019', '146028', '146044', '146294', '146358', '147000', '147524', '147600', '148000', '148100', '148300', '148421', '148512', '148592', '148725', '148748', '148765', '148801', '148843', '14900', '149000', '149097', '149315', '14940', '149400', '149657', '149712', '149750', '149760', '149805', '149833', '15', '150', '150000', '15005', '150211', '150225', '150560', '150572', '150597', '150624', '150721', '150872', '150963', '151000', '151033', '151068', '151136', '151444', '151523', '151731', '151976', '152000', '152153', '152317', '152389', '152413', '152530', '152561', '152688', '153000', '153132', '153173', '153219', '153235', '153383', '153527', '153660', '153992', '154000', '154100', '154111', '154199', '154284', '154954', '155000', '155082', '15551', '155566', '155761', '155889', '156000', '156126', '156187', '156200', '156340', '156617', '156919', '156927', '157000', '157040', '157244', '157897', '157900', '158000', '158112', '159000', '159015', '159057', '159216', '159850', '159999', '16', '16000', '160000', '160100', '160143', '160183', '160217', '16058', '160800', '160845', '16099', '161000', '161199', '161210', '161322', '161492', '162000', '16201', '16204', '162280', '162340', '162856', '162892', '163000', '163110', '16343', '163431', '163460', '163522', '163535', '163720', '164000', '164144', '164273', '164395', '164434', '164671', '164700', '164740', '164875', '164905', '164998', '165000', '165123', '165141', '165313', '16543', '165438', '165558', '165572', '166000', '166488', '166981', '167000', '167234', '167256', '167350', '167500', '167898', '168000', '168259', '168555', '168716', '168750', '169000', '169096', '169318', '169540', '169798', '170', '17000', '170000', '170371', '170451', '171000', '171100', '171264', '171377', '171434', '171740', '171928', '171988', '172157', '173000', '173048', '173118', '173301', '173399', '174000', '174461', '174563', '174900', '175000', '175809', '176000', '176213', '176236', '17625', '17664', '176885', '177000', '178000', '178123', '178824', '179000', '179192', '179241', '17995', '18', '180000', '180101', '180415', '180637', '18066', '180946', '181000', '181500', '181578', '182000', '182340', '182925', '183000', '183268', '183323', '183818', '184281', '18477', '18555', '186000', '186390', '186455', '18648', '186550', '186670', '187000', '187003', '187073', '187156', '187169', '187193', '187290', '187429', '187765', '188000', '188345', '18874', '189000', '189992', '19000', '190000', '191000', '191019', '191200', '192000', '192069', '192800', '193000', '193375', '194236', '19491', '19500', '195000', '197000', '197252', '197543', '197600', '198000', '198100', '198500', '198780', '198841', '199000', '199100', '199200', '20000', '200000', '200093', '200200', '201341', '201515', '20169', '202500', '203000', '20400', '204125', '20500', '205378', '205519', '207', '207000', '207468', '208000', '208377', '20846', '20860', '20897', '2097', '210400', '21112', '211360', '211800', '21238', '212875', '213000', '213159', '21405', '214644', '215000', '215436', '217000', '21721', '218000', '219', '219000', '220000', '22073', '221300', '222039', '223000', '22400', '22500', '225000', '226000', '226886', '226896', '22700', '227000', '227379', '228000', '228771', '231000', '232444', '23275', '23381', '23500', '236000', '236738', '238050', '23937', '23939', '24000', '240000', '24200', '242000', '242989', '243650', '24473', '24500', '24566', '246500', '24663', '24739', '24956', '2500', '25000', '25120', '251332', '25280', '25400', '25536', '256200', '25743', '258000', '259532', '25970', '26000', '262000', '262287', '26314', '26380', '264000', '26500', '265000', '26600', '267000', '26771', '268212', '2700', '27001', '27050', '27300', '27470', '277710', '27847', '27910', '28000', '280300', '28083', '28126', '28553', '289499', '29000', '295000', '29850', '3000', '30000', '300000', '30278', '30300', '303100', '30371', '30392', '30633', '30827', '31286', '313700', '31556', '31691', '31700', '31888', '32000', '32101', '32120', '32475', '32575', '33000', '33090', '33135', '33484', '33600', '33776', '33874', '34000', '3425', '34345', '34652', '35000', '351', '35222', '35577', '35599', '35660', '35823', '35947', '36363', '36433', '36699', '36898', '37000', '37133', '37199', '37325', '37415', '37481', '37801', '37982', '38000', '38412', '38524', '38718', '38781', '39061', '39130', '39335', '39593', '39600', '40243', '403', '40385', '40551', '40727', '40876', '40900', '40961', '41000', '41190', '41305', '41506', '41640', '41900', '42000', '42012', '42014', '42054', '42056', '42149', '43000', '43321', '43500', '43568', '43609', '43655', '44000', '44215', '4444', '44492', '44500', '44535', '44595', '44600', '44607', '44680', '44800', '45000', '45059', '45200', '45502', '45600', '45952', '46000', '46175', '46176', '46200', '46225', '46296', '46453', '46700', '46886', '46920', '46926', '47000', '47292', '47449', '4750', '47605', '47914', '48000', '48304', '48483', '49237', '49272', '49302', '49304', '49344', '49349', '49455', '49500', '49511', '49589', '49600', '49721', '49799', '49950', '50000', '50032', '50242', '50331', '50672', '50874', '51000', '51100', '51181', '51200', '51360', '51676', '51752', '51809', '52000', '52350', '52399', '52500', '52600', '52626', '52658', '52743', '52891', '53000', '53400', '53588', '53675', '53683', '53800', '53913', '53993', '54000', '54161', '54484', '54526', '54696', '54700', '54879', '54899', '55000', '55035', '55061', '55205', '55359', '55986', '56000', '56006', '56019', '56500', '56606', '56796', '56894', '57000', '57020', '57027', '57300', '57499', '58000', '58288', '58300', '58489', '58514', '58572', '58692', '58754', '58950', '5900', '59000', '5925', '59300', '59478', '59500', '59676', '59747', '59880', '59882', '600', '60000', '60148', '60219', '60245', '60303', '60467', '60785', '61000', '61012', '61035', '61119', '61180', '61194', '61235', '61304', '61500', '61750', '62000', '62155', '62167', '62200', '62235', '62327', '62400', '62463', '62495', '62686', '62700', '62708', '62750', '62832', '62893', '63000', '63025', '63103', '63212', '63281', '63496', '63633', '63746', '63807', '63924', '64000', '64100', '64400', '64500', '64904', '64920', '64960', '65000', '6512', '65123', '6513', '65160', '65200', '65444', '65500', '65557', '65720', '65722', '65765', '65821', '65900', '65955', '66000', '66333', '66373', '66415', '66500', '66512', '66675', '66894', '6700', '67000', '67037', '67053', '67100', '67155', '67200', '67349', '67395', '67595', '67600', '67622', '67740', '67966', '68000', '68004', '68139', '6837', '68380', '68400', '68449', '68464', '68465', '68533', '68565', '68591', '68609', '68676', '68760', '68972', '69000', '69097', '69251', '69285', '69340', '69393', '69400', '69500', '69528', '69551', '69615', '69671', '69700', '69800', '69998', '70000', '70179', '70190', '70247', '70300', '70311', '70343', '70417', '70550', '70816', '71000', '71149', '71190', '71208', '71300', '71447', '71500', '71725', '71842', '71890', '71910', '71914', '72', '7200', '72000', '72050', '72142', '72394', '72400', '72486', '72608', '72871', '72939', '73000', '73357', '73372', '73377', '73398', '73500', '73503', '73511', '73600', '73692', '73712', '73745', '73758', '7378', '73800', '73876', '74000', '74046', '74063', '7413', '74169', '74200', '74468', '74486', '74819', '74900', '74962', '75000', '75217', '75290', '75325', '75526', '75546', '75594', '75957', '76000', '76117', '76122', '76300', '76369', '76413', '76426', '76450', '76500', '76591', '76605', '76812', '76858', '76884', '77000', '77202', '77204', '77309', '77447', '77571', '77698', '77770', '77793', '77983', '78000', '78038', '78141', '78448', '78526', '78536', '78554', '78620', '78705', '78945', '79000', '79083', '79112', '79232', '79254', '79503', '79678', '79800', '80000', '80119', '80123', '80166', '80286', '80380', '80400', '80465', '8047', '80500', '80527', '80537', '80628', '80645', '80707', '80762', '80779', '80900', '8100', '81000', '81171', '81195', '81376', '81423', '81451', '81456', '81662', '81712', '81713', '81860', '81990', '82000', '82024', '82055', '82170', '82177', '82235', '82420', '82500', '82608', '82915', '83000', '83181', '83300', '83311', '83314', '83433', '83650', '83683', '83888', '83945', '83946', '84000', '84037', '84449', '84771', '84817', '85000', '85043', '85049', '85140', '85167', '85179', '85185', '85269', '85331', '85386', '85555', '85605', '85628', '85655', '85826', '85843', '85965', '8600', '86000', '86022', '86173', '86433', '86524', '86639', '86771', '86847', '87000', '87014', '87108', '87300', '87397', '87457', '87501', '87548', '87549', '87612', '87706', '87740', '87777', '87800', '87836', '87839', '87896', '88000', '88014', '88102', '88205', '88208', '88282', '88372', '88410', '88432', '88433', '88454', '88459', '88870', '89000', '8908', '89085', '89100', '89130', '89236', '89469', '89472', '89769', '89800', '89900', '89914', '89953', '90000', '90129', '90188', '90248', '90255', '90384', '90422', '90460', '90500', '90505', '90604', '90804', '90817', '90937', '90987', '91000', '91036', '91115', '91132', '91200', '91230', '91294', '91331', '91442', '91500', '91533', '91626', '91766', '91924', '91992', '92000', '92176', '92177', '92246', '92275', '92280', '92292', '92343', '92500', '92578', '92645', '92672', '92792', '92996', '93000', '93208', '93300', '93416', '93476', '93629', '93660', '93752', '93822', '93900', '94', '9400', '94000', '94095', '94115', '94307', '94323', '94383', '94423', '94450', '94503', '94731', '94822', '94847', '94970', '95000', '95037', '95052', '95122', '95179', '95238', '9533', '95356', '95538', '95664', '95974', '95990', '96000', '96068', '96100', '96200', '96222', '96256', '96539', '96640', '96666', '96833', '96834', '96998', '97000', '97150', '97185', '97310', '97319', '97456', '97487', '97500', '97557', '97751', '97776', '97810', '97873', '97987', '9800', '98000', '98161', '98245', '98352', '98400', '98405', '98406', '98588', '98650', '98651', '98703', '98740', '98854', '99000', '99058', '99154', '99200', '99274', '99343', '99373', '99425', '99450', '99471', '99500', '99517', '99564', '99645', '99734', '99806', '99855', '99930', '999999', '9999999']\n",
      "7 ['clean', 'lien', 'missing', 'parts only', 'rebuilt', 'salvage']\n",
      "8 ['4wd', 'fwd', 'rwd']\n"
     ]
    }
   ],
   "source": [
    "# these will be our columns\n",
    "columns = [\"price\", \"year\", \"manufacturer\", \"model\", \"condition\", \"fuel\", \"odometer\", \"title_status\", \"transmission\"]\n",
    "# this will contain our converters\n",
    "colValues = {}\n",
    "\n",
    "# first we load our data as strings so we can define the converters\n",
    "data = np.array(np.genfromtxt('data/vehicles.csv', delimiter=',', usecols=(1,2,3,4,5,7,8,9,11), skip_header=1, dtype=str, encoding='utf-8'))  \n",
    "\n",
    "# make a list of the unique values in each column of our data\n",
    "for colIndex in range(data.shape[1]):\n",
    "    colValues[colIndex] = np.unique(data[:, colIndex]).tolist()\n",
    "    print(colIndex, colValues[colIndex])\n",
    "\n",
    "# map values to their indices in the list of unique values\n",
    "def converter(x, colIndex):\n",
    "    return colValues[colIndex].index(x)\n",
    "    \n",
    "data = np.array(np.genfromtxt('data/vehicles.csv', delimiter=',', usecols=(1,2,3,4,5,7,8,9,11), converters={3: lambda x: converter(x, 2), 4: lambda x: converter(x, 3), 5: lambda x: converter(x, 4), 7: lambda x: converter(x,5), 9: lambda x: converter(x, 7), 11: lambda x: converter(x, 8)}, skip_header=1, dtype=int, encoding='utf-8'))  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "68a5a5ca",
   "metadata": {},
   "source": [
    "Then we get summary statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f0dcff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min, max, mean, std per variable\n",
      "              0            1         2           3         4         5  \\\n",
      "0      0.000000  1999.000000  0.000000    0.000000  0.000000  0.000000   \n",
      "1  55000.000000  2021.000000  1.000000  340.000000  5.000000  4.000000   \n",
      "2   7978.281507  2012.381887  0.445535  159.225142  1.061431  2.012350   \n",
      "3   5542.906703     3.997048  0.497025   96.160745  1.225660  0.138432   \n",
      "\n",
      "              6         7         8  \n",
      "0  0.000000e+00  0.000000  0.000000  \n",
      "1  9.999999e+06  5.000000  2.000000  \n",
      "2  1.124405e+05  0.209943  0.886954  \n",
      "3  2.546163e+05  0.910812  0.424340  \n",
      "shape\n",
      "((3158, 9), dtype('int64'))\n"
     ]
    }
   ],
   "source": [
    "def getSummaryStatistics(data):\n",
    "    print(\"min, max, mean, std per variable\")\n",
    "    return pd.DataFrame([data.min(axis=0), data.max(axis=0), data.mean(axis=0), data.std(axis=0)])\n",
    "\n",
    "def getShapeType(data):\n",
    "    print(\"shape\")\n",
    "    return (data.shape, data.dtype)\n",
    "\n",
    "print(getSummaryStatistics(data))\n",
    "print(getShapeType(data))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ef7fcc85",
   "metadata": {},
   "source": [
    "# Split the data\n",
    "\n",
    "If we are doing supervised machine learning, we split the data into train and test. \n",
    "\n",
    "However, here we are doing clustering, so we don't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8431e70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "283ad7b8",
   "metadata": {},
   "source": [
    "If we had a clear dependent variable (as we do with the car logo dataset) we'd strip it off. However, here we don't.\n",
    "\n",
    "\n",
    "no depdnet varibale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2566b236",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train = train[:, -1]\n",
    "#x_train = train[:, 0:-1]\n",
    "#y_test = test[:, -1]\n",
    "#x_test = test[:, 0:-1]\n",
    "x_train = train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c0695d83",
   "metadata": {},
   "source": [
    "# Normalization Review\n",
    "\n",
    "Here we implement max-min global, max-min local, z-score and center. This code comes from day 20.\n",
    "\n",
    "This code you can use as a **tool**.\n",
    "\n",
    "**If you are using separate training and test data, you want to normalize to the mean (min, max, std) of the _training data_.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2fa19fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data, min, max, mean, std, method='center'):\n",
    "    if method == 'center':\n",
    "        return data - mean\n",
    "    elif method == 'max-min-global':\n",
    "        return (data - min) / (max - min)\n",
    "    elif method == 'max-min-local':\n",
    "        return (data - min) / (max - min)\n",
    "    elif method == 'zscore':\n",
    "        return (data - mean) / std\n",
    "    else:\n",
    "        raise Exception(\"I can't do \" + method)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f5352ca4",
   "metadata": {},
   "source": [
    "Let's try it!\n",
    "\n",
    "**When you are doing supervised machine learning, you always want to normalize using statistics (mean, min, max) from your training data**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "938d3811",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_g = np.min(x_train)\n",
    "max_g = np.max(x_train)\n",
    "min_l = np.min(x_train, axis=0)\n",
    "max_l = np.max(x_train, axis=0)\n",
    "mean = np.mean(x_train, axis=0)\n",
    "std = np.std(x_train, axis=0)\n",
    "normalized_train = normalize(x_train, min_l, max_l, mean, std, method='max-min-local')\n",
    "# normalized_train = normalize(train, min_g, max_g, mean, std, method='center')\n",
    "# normalized_train = normalize(train, min_g, max_g, mean, std, method='max-min-global')\n",
    "# normalized_train = normalize(train, min_g, max_g, mean, std, method='zscore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ad0b841e",
   "metadata": {},
   "source": [
    "# K-means Clustering Review\n",
    "\n",
    "The code below comes from day 22.\n",
    "\n",
    "You can use this code as a **tool**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3f7babe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Euclidean distance\n",
    "def distance(a, b):\n",
    "    subtracted = a-b\n",
    "    return np.sqrt(np.dot(subtracted.T, subtracted))\n",
    "\n",
    "# Calculate the distance from each data point to each centroid\n",
    "def get_distances(item, centroids):\n",
    "    return [distance(item, centroid) for centroid in centroids]\n",
    "\n",
    "# Update cluster assignments given a set of centroids\n",
    "# input: list of data points, initial list of centroids\n",
    "def update_clusters(data, centroids):\n",
    "    # initialize clusters\n",
    "    clusters = {}\n",
    "    for i in range(len(centroids)):\n",
    "        # set its cluster members to the empty list\n",
    "        clusters[i] = []\n",
    "    # initialize mappings\n",
    "    mappings = {}\n",
    "    # for each data point\n",
    "    for j, datum in enumerate(data):\n",
    "        # find the index of the centroid with the smallest distance to this data point\n",
    "        min_cluster_index = np.argmin(get_distances(datum, centroids))\n",
    "        # add this data point to that centroid's cluster\n",
    "        clusters[min_cluster_index].append(datum)\n",
    "        # add mapping\n",
    "        mappings[j] = min_cluster_index\n",
    "    return clusters, mappings\n",
    "\n",
    "# Update the centroids given the data\n",
    "def update_centroids(clusters, oldcentroids):\n",
    "    # set centroids to empty list\n",
    "    centroids = []\n",
    "    # for each set of data points in a cluster around a single centroid\n",
    "    for centroidid, data_in_cluster in clusters.items():\n",
    "        # graciously handle case where no data ended up in a cluster\n",
    "        if len(data_in_cluster) > 0:\n",
    "            # new centroid is the mean of that cluster\n",
    "            centroids.append(np.mean(data_in_cluster, axis=0))\n",
    "        else:\n",
    "            centroids.append(oldcentroids[centroidid])\n",
    "    return centroids\n",
    "\n",
    "# Measure the inertia\n",
    "def inertia(data, centroids, clusters):\n",
    "    sum = 0\n",
    "    for i in clusters.keys():\n",
    "        for datum in clusters[i]:\n",
    "            # calculate the distance squared between each data point and its centroid\n",
    "            sum += distance(datum, centroids[i])**2\n",
    "    # average over the data\n",
    "    return sum / len(data)\n",
    "\n",
    "def fit_kmeans(data, k, cutoff=1):\n",
    "    # make some initial centroids\n",
    "    centroids = np.array([data[x] for x in np.random.choice(np.arange(len(data)), size=k, replace=False)])\n",
    "    # initialize last_inertia\n",
    "    last_inertia = -1\n",
    "    while True:\n",
    "        # get the clusters for these centroids\n",
    "        clusters, mappings = update_clusters(data, centroids)\n",
    "        # calculate the inertia for this clustering\n",
    "        this_inertia = inertia(data, centroids, clusters)\n",
    "        # stop when the inertia stops changing very much\n",
    "        if last_inertia > 0 and abs(last_inertia - this_inertia) < cutoff:\n",
    "            break\n",
    "        last_inertia = this_inertia\n",
    "        # update the centroids\n",
    "        centroids = update_centroids(clusters, centroids)\n",
    "    return centroids, clusters, mappings, this_inertia"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "78e7adea",
   "metadata": {},
   "source": [
    "On Wednesday we talked about the Silhouette coefficient as a way to evaluate the goodness of a clustering. We will use the scikit-learn implementation today."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21ff6a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "s = silhouette_score(data, mappings/labels, metric='euclidean')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "064c2fbf",
   "metadata": {},
   "source": [
    "# Impact of normalization on K-Means clustering\n",
    "\n",
    "Fill in this table.\n",
    "1. Try all the types of normalization plus k-means clustering. Use a reasonable value for $k$ in k-means clustering, like 6 (maybe it will cluster them by condition!).\n",
    "2. Try at least one type of normalization (centering!) plus PCA plus k-means clustering. Use the same value of $k$ for k-means clustering as you have so far. Pick a number of principal components that lets you keep at least 80% of the cumulative sum of variance.\n",
    "\n",
    "| Normalization | PCA (None or k) | K-means k | Silhouette score | Time |\n",
    "| ------------- | --------------- | --------- | ---------------- | ---- |\n",
    "| None | None | 7 | 0.49563619444703105| 6.2|\n",
    "| Centering | None | 7 | 0.49563619443355067| 7.39|\n",
    "| Max-min global | None | 7 | 0.44644257060903064 | 6.2 |\n",
    "| Max-min local | None | 7 | 0.34687496989437483| 5.48 |\n",
    "| Z-score | None | 7| 0.1566625885440842 | 5.48|\n",
    "| ?? | ?? | 7 | | |\n",
    "\n",
    "\n",
    "\n",
    "higher k, lower SC more clusters more overalap\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6a45aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a22199c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_g = np.min(x_train)\n",
    "max_g = np.max(x_train)\n",
    "min_l = np.min(x_train, axis=0)\n",
    "max_l = np.max(x_train, axis=0)\n",
    "mean = np.mean(x_train, axis=0)\n",
    "std = np.std(x_train, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "631a3a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
      "Wall time: 7.39 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.49563619443355067"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time \n",
    "\n",
    "normalized_train = normalize(x_train, min_g, max_g, mean, std, method='center')\n",
    "centroids, clusters, mappings, _ = fit_kmeans(normalized_train, k)\n",
    "silhouette_score(normalized_train, [x[1] for x in sorted(mappings.items())], metric='euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8a9546c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
      "Wall time: 6.2 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.44644257060903064"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time \n",
    "\n",
    "normalized_train = normalize(x_train, min_g, max_g, mean, std, method='max-min-global')\n",
    "centroids, clusters, mappings, _ = fit_kmeans(normalized_train, k)\n",
    "silhouette_score(normalized_train, [x[1] for x in sorted(mappings.items())], metric='euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58396e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 5.48 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.34687496989437483"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time \n",
    "\n",
    "normalized_train = normalize(x_train, min_g, max_g, mean, std, method='max-min-local')\n",
    "centroids, clusters, mappings, _ = fit_kmeans(normalized_train, k)\n",
    "silhouette_score(normalized_train, [x[1] for x in sorted(mappings.items())], metric='euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f313dc01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 5.48 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1566625885440842"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time \n",
    "\n",
    "normalized_train = normalize(x_train, min_g, max_g, mean, std, method='zscore')\n",
    "centroids, clusters, mappings, _ = fit_kmeans(normalized_train, k)\n",
    "silhouette_score(normalized_train, [x[1] for x in sorted(mappings.items())], metric='euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce70a916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
      "Wall time: 6.2 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.49563619444703105"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time \n",
    "\n",
    "normalized_train = train\n",
    "centroids, clusters, mappings, _ = fit_kmeans(normalized_train, k)\n",
    "silhouette_score(normalized_train, [x[1] for x in sorted(mappings.items())], metric='euclidean')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4f6384d4",
   "metadata": {},
   "source": [
    "**Bonus**: Now think about PCA. If we had a dataset with 1000 independent variables (like our car logo data), what do you think might be the impact of PCA-first on silhouette coefficient, and on time?\n",
    "\n",
    "\n",
    "better clustering \n",
    "\n",
    "more time efficient\n",
    "\n",
    "\n",
    "for k nearest neighbors:\n",
    "more time efficient, but can not say about accuracy until actually do it"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fdab4382",
   "metadata": {},
   "source": [
    "Parameters in common with k nearest neighbors and k means clusters are k and distance\n",
    "K means lcusters versus k means neighbors:\n",
    "k is how many clusyers or how many neighbors to look at when making classification decision. Depndent vairable in this is given by y variable \n",
    "\n",
    "\n",
    "for k means lcustering, the less norrmlaization the better\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b96842b3",
   "metadata": {},
   "source": [
    "SIlhouette coefiicient ranges from -1 to 1\n",
    "\n",
    "tight clusters are closest to 1\n",
    "\n",
    "if 0 menas cluster overalpss\n",
    "\n",
    "if - means wrong cluster assisgnmnet \n",
    "\n",
    "for k nearest neighbors, the fewer neighbors the more time efficient. Use elbow plot of accuracy and k. \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3ad99094",
   "metadata": {},
   "source": [
    "smaller distances with min max local, more overallping clusters\n",
    "\n",
    "z score will make everyhting closer, more overalaping clusters \n",
    "\n",
    "accuracy ranges from 0 to 1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "3ad933181bd8a04b432d3370b9dc3b0662ad032c4dfaa4e4f1596c548f763858"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
