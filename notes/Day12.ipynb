{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "811722d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6243b190",
   "metadata": {},
   "source": [
    "# Review\n",
    "\n",
    "The first three steps in data science are to:\n",
    "* ??\n",
    "* ??\n",
    "* ??\n",
    "\n",
    "Today we will keep working with the set of Craigslist listings for used cars.\n",
    "* Where did it come from?\n",
    "* What does it look like?\n",
    "* What types of cleaning have I done to it and what types do I still ahve to do?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cd3775ce",
   "metadata": {},
   "source": [
    "Now we will load this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca359103",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "data/vehiclesNumeric.csv not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Load the data\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# This dataset is the mazda subsample from https://www.kaggle.com/austinreese/craigslist-carstrucks-data after some cleanup\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m data \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(np\u001b[39m.\u001b[39;49mgenfromtxt(\u001b[39m'\u001b[39;49m\u001b[39mdata/vehiclesNumeric.csv\u001b[39;49m\u001b[39m'\u001b[39;49m, delimiter\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m,\u001b[39;49m\u001b[39m'\u001b[39;49m, skip_header\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, dtype\u001b[39m=\u001b[39;49m\u001b[39mint\u001b[39;49m, encoding\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m'\u001b[39;49m, usecols\u001b[39m=\u001b[39;49m[\u001b[39m1\u001b[39;49m,\u001b[39m2\u001b[39;49m]))  \n\u001b[1;32m      5\u001b[0m \u001b[39mprint\u001b[39m(data)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/numpy/lib/npyio.py:1977\u001b[0m, in \u001b[0;36mgenfromtxt\u001b[0;34m(fname, dtype, comments, delimiter, skip_header, skip_footer, converters, missing_values, filling_values, usecols, names, excludelist, deletechars, replace_space, autostrip, case_sensitive, defaultfmt, unpack, usemask, loose, invalid_raise, max_rows, encoding, ndmin, like)\u001b[0m\n\u001b[1;32m   1975\u001b[0m     fname \u001b[39m=\u001b[39m os_fspath(fname)\n\u001b[1;32m   1976\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(fname, \u001b[39mstr\u001b[39m):\n\u001b[0;32m-> 1977\u001b[0m     fid \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mlib\u001b[39m.\u001b[39;49m_datasource\u001b[39m.\u001b[39;49mopen(fname, \u001b[39m'\u001b[39;49m\u001b[39mrt\u001b[39;49m\u001b[39m'\u001b[39;49m, encoding\u001b[39m=\u001b[39;49mencoding)\n\u001b[1;32m   1978\u001b[0m     fid_ctx \u001b[39m=\u001b[39m contextlib\u001b[39m.\u001b[39mclosing(fid)\n\u001b[1;32m   1979\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/numpy/lib/_datasource.py:193\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[39mOpen `path` with `mode` and return the file object.\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    189\u001b[0m \n\u001b[1;32m    190\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    192\u001b[0m ds \u001b[39m=\u001b[39m DataSource(destpath)\n\u001b[0;32m--> 193\u001b[0m \u001b[39mreturn\u001b[39;00m ds\u001b[39m.\u001b[39;49mopen(path, mode, encoding\u001b[39m=\u001b[39;49mencoding, newline\u001b[39m=\u001b[39;49mnewline)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/numpy/lib/_datasource.py:533\u001b[0m, in \u001b[0;36mDataSource.open\u001b[0;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[39mreturn\u001b[39;00m _file_openers[ext](found, mode\u001b[39m=\u001b[39mmode,\n\u001b[1;32m    531\u001b[0m                               encoding\u001b[39m=\u001b[39mencoding, newline\u001b[39m=\u001b[39mnewline)\n\u001b[1;32m    532\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 533\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mpath\u001b[39m}\u001b[39;00m\u001b[39m not found.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: data/vehiclesNumeric.csv not found."
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "# This dataset is the mazda subsample from https://www.kaggle.com/austinreese/craigslist-carstrucks-data after some cleanup\n",
    "\n",
    "data = np.array(np.genfromtxt('data/vehiclesNumeric.csv', delimiter=',', skip_header=1, dtype=int, encoding='utf-8', usecols=[1,2]))  \n",
    "print(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "68a5a5ca",
   "metadata": {},
   "source": [
    "Let's get some summary statistics so we can see what's going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0dcff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSummaryStatistics(data):\n",
    "    print(\"min, max, mean, std per variable\")\n",
    "    ??\n",
    "\n",
    "def getShapeType(data):\n",
    "    print(\"shape\")\n",
    "    ??\n",
    "\n",
    "print(getSummaryStatistics(data))\n",
    "print(getShapeType(data))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c2b850ff",
   "metadata": {},
   "source": [
    "## Let's review regression\n",
    "\n",
    "Regression allows us to:\n",
    "* determine the *nature* of a relationship between one (or more!) independent variables and a dependent variable\n",
    "* determine the *strength* of the relationship\n",
    "\n",
    "Regression *fits* a function to a dataset.\n",
    "\n",
    "Regression is *not* the same as interpolation. Why not?\n",
    "\n",
    "In order to define regression, we need three things. And they are?\n",
    "* function (a line)\n",
    "* a method for fitting the function to the data\n",
    "* a measure of goodness of fit"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "71ac8405",
   "metadata": {},
   "source": [
    "## What kinds of functions can we fit? \n",
    "\n",
    "We are going to start with *linear regression*. What type of function do we fit when we do linear regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152211ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiply the xs by the m and add b\n",
    "def linear_regression(x, m, b):\n",
    "    return x*m+b\n",
    "\n",
    "# Mean sum of squared errors; why squared?\n",
    "def msse(y, yhat):\n",
    "    r = y\n",
    "    return r\n",
    "\n",
    "def plotxyyhat(x, y, yhat):\n",
    "    plt.plot(x, y, 'o', label='data')\n",
    "    plt.plot(x, yhat, label='least squares fit, $y = mx + b$')\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.legend(framealpha=1, shadow=True)\n",
    "    plt.grid(alpha=0.25)\n",
    "    plt.show()\n",
    "\n",
    "# x is model year\n",
    "x = data[:, 1]\n",
    "\n",
    "# y is price\n",
    "y = data[:, 0]\n",
    "\n",
    "# calculate yhat, using the mean as the intercept and the 0 as the slope\n",
    "yhat = linear_regression(x, 0, y.mean())\n",
    "print(msse(y, yhat))\n",
    "\n",
    "plotxyyhat(x, y, yhat)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c6f44154",
   "metadata": {},
   "source": [
    "## What does it mean to *fit* a function? \n",
    "\n",
    "Now let's talk about methods for making the function \"fit\" the data. We know $x$, and we know $y$. We do *not* know the values for $b$ or $m$; that's what we need to figure out. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e68cca9b",
   "metadata": {},
   "source": [
    "The function \"lstsq\" in the scipy package's linalg (linear algebra) subpackage\n",
    "fits a linear regression using least squares. It gives us predicted $y$ values $\\hat{y}$ and residuals for each $\\hat{y}$. Let's try it on our data.\n",
    "\n",
    "lstsq will not always work for certain data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8893fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.linalg as sp_la\n",
    "\n",
    "def fit(data, independent, dependent): #independent is like 1 orr 0 index of columns\n",
    "    # These are our independent variable(s)\n",
    "    x = data[:, independent]\n",
    " \n",
    "    # We add a column of 1s for the intercept\n",
    "    A = x[:, np.newaxis]**[0, 1] #np.newaxis are the x values and so is :\n",
    "    A = x[:, np.newaxis, np.newaxis]**[0, 1,2] #np.newaxis are the x values\n",
    "    print(A.shape)\n",
    "\n",
    "    # This is the dependent variable \n",
    "    y = data[:, dependent]\n",
    " \n",
    "    # This is the regression coefficients that were fit, plus some other results\n",
    "    c, res, _, _ = sp_la.lstsq(A, y)\n",
    "\n",
    "    return c, res\n",
    "\n",
    "c, res = fit(data, 1, 0)\n",
    "# this is b and m!\n",
    "print(c)\n",
    "yhat = linear_regression(data[:, 1], c[1], c[0])\n",
    "print(msse(data[:,0],yhat))\n",
    "plotxyyhat(data[:, 1], data[:, 0], yhat)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1c3e077a",
   "metadata": {},
   "source": [
    "Well, that certainly fits the data better than our previous guess."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "803b904a",
   "metadata": {},
   "source": [
    "## And, this is a function we can use to predict the $y$ (calculate the $\\hat{y}$) for new $x$s, so it's a *model*!\n",
    "\n",
    "For example, my car was a 2016 Hyundai, so what should its Craigslist price be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ff2ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(??)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "55025d54",
   "metadata": {},
   "source": [
    "*What about your Hyundais??*\n",
    "\n",
    "Of course, this model is based on *historical* car prices, and what has happened over the past six months?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "df1778c8",
   "metadata": {},
   "source": [
    "## How do we know how well our model works?\n",
    "\n",
    "In order to see how well our model works, we could just calculate the MSSE on our data. But that won't tell us how well our model *generalizes* to data it hasn't seen before. In order to do that, we need a *held-out test set*. And then we would calculate how well the regression predictions matched the true prices for the held-out data. In particular, we would calculate $$R^2 = 1 - \\frac{\\sum_{i=1}^N (y_i - \\hat{y})^2}{\\sum_{i=1}^N (y_i - \\bar{y})^2}$$\n",
    "The numerator there tells us the error of the model (vs just calculating the mean of the data) and the denominator tells us the error of the data vs the mean of the data. We use this instead of MSSE, because it tells us how well our model outperforms a really stupid model (just use the mean of the data).\n",
    "\n",
    "In fact, the numerator is the residuals! So we can rewrite this as $$R^2 = 1 - \\frac{r_i^2}{\\sum_{i=1}^N (y_i - \\bar{y})^2}$$\n",
    "\n",
    "Let's split our data into **train** and **test**. Let's make sure and sort by time first, because we don't want to let the future predict the past.\n",
    "\n",
    "time in vehicles, sort it by time, so future does not predict past\n",
    "\n",
    "iris data is already sorted, so scramble it so linera regression fits whole data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5d73f67b",
   "metadata": {},
   "source": [
    "0/0 equals =1 if the dubbest model in demoniator is best model (so residual-0, no dif between every y point and y bar)\n",
    "\n",
    "otherwise, use other equation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d2a74de4",
   "metadata": {},
   "source": [
    "how much better is this model then the dubbest possible model, where m=0 and b=Y mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa97f2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data[:, 1].argsort()]          # sorts data by time\n",
    "print(getSummaryStatistics(data)) #should be the same \n",
    "print(getShapeType(data))\n",
    "\n",
    "(train, test) = np.split(data, [int(len(data) / 10 * 8)]) #80% in train 20% in test \n",
    "print(train.shape, test.shape)\n",
    "\n",
    "#have line but don't intercept and m, input data to calcualte b and m (train)\n",
    "#how well does the line generate to new data, test model for how genralizes "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b253dab6",
   "metadata": {},
   "source": [
    "Then, let's use the *train* data to fit the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802f5194",
   "metadata": {},
   "outputs": [],
   "source": [
    "c, res = fit(train, 1, 0)\n",
    "# this is b and m!\n",
    "print(c, res)\n",
    "\n",
    "yhat = linear_regression(train[:, 1], c[1], c[0])\n",
    "print(yhat.shape)\n",
    "plotxyyhat(train[:, 1], train[:, 0], yhat)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b53956aa",
   "metadata": {},
   "source": [
    "Then let's use the test data to evaluate our model:\n",
    "* We will take the model we fit (the prediction function we fit) to our *training data*\n",
    "* We will use it to predict values for the new data, the *test data*\n",
    "* We will measure how well the model does at predicting\n",
    "\n",
    "Just above when we fit the model, we calculated $$ A \\cdot \\vec{c} = \\vec{\\hat{y}} $$\n",
    "and we knew $A$ and $\\vec{y}$.\n",
    "\n",
    "Now we know $A$ and $\\vec{c}$ and we want to calculate $\\vec{\\hat{y}}$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d19f36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data, independent, c):\n",
    "    # These are our independent variable(s)\n",
    "    x = data[:, independent]\n",
    "    \n",
    "\n",
    "    # We add a column of 1s for the intercept\n",
    "    A = x[:, np.newaxis]**[0, 1]\n",
    "\n",
    "    return np.dot(A,c)\n",
    "\n",
    "yhat = predict(test, 1, c)\n",
    "plotxyyhat(test[:, 1], test[:, 0], yhat)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a0338299",
   "metadata": {},
   "source": [
    "fit and train are exact same thing\n",
    "\n",
    "test=      predicted value-actual value for that \n",
    "\n",
    "test is when calcuating residuals for all the test data (predicted points)\n",
    "\n",
    "\n",
    "predicitng is just inferring a price for a given x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fec395a9",
   "metadata": {},
   "source": [
    "Compare the *fit* on the test data to the *fit* on the training data. What do you think?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac4b15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume these are numpy arrays\n",
    "def rsquared(y, yhat):\n",
    "    if len(y) != len(yhat):\n",
    "        print(\"Need y and yhat to be the same length!\")\n",
    "        return 0\n",
    "    return ??\n",
    "\n",
    "yhat = predict(train, 1, c)\n",
    "print(rsquared(train[:, 0], yhat))\n",
    "yhat = predict(test, 1, c)\n",
    "print(rsquared(test[:, 0], yhat))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "637f74fa",
   "metadata": {},
   "source": [
    "How does $R^2$ resemble $MSSE$, and how not? What does $R^2$ look like when the dependent variable is very highly correlated with the independent variable, for example they are the same? What does it look like when they are not at all correlated?\n",
    "\n",
    "Let's come back to this notion of *correlation*. If two variables are highly *correlated* then a linear regression calculated using one of them as the independent variable and the other as the dependent variable will have *what size of* $R^2$? \n",
    "\n",
    "If two variables are highly correlated does this mean one *caused* the other? Why or why not?\n",
    "\n",
    "\n",
    "higher r squared as approaches 1, mean square decreases\n",
    "\n",
    "fit- figure out independy vairable, add column of 1s\n",
    "\n",
    "preidt get indpendent variable, add 1, have a and c do dot product"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3480d4",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
